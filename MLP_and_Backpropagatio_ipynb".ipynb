{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vacheharutyunyan/machine-learning-projects/blob/main/MLP_and_Backpropagatio_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53ecd297-adee-4e74-b7da-1e674c69e38f",
      "metadata": {
        "id": "53ecd297-adee-4e74-b7da-1e674c69e38f"
      },
      "source": [
        "# Part 0: Differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae696334-4ac1-4ca1-9c8c-c8c8ee1f63ae",
      "metadata": {
        "id": "ae696334-4ac1-4ca1-9c8c-c8c8ee1f63ae"
      },
      "source": [
        "Please show the derivation to each answer for each problem. Use LaTeX to write up the answers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7fe5ef6-5c64-49c7-8aad-b2d49412d00e",
      "metadata": {
        "id": "a7fe5ef6-5c64-49c7-8aad-b2d49412d00e"
      },
      "source": [
        "## Exercise 1:\n",
        "$$  \n",
        "y = x^Tx,  \\quad x \\in \\mathbb{R}^N\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9e4e3fe-c620-4996-8650-1b1ff23d7c2f",
      "metadata": {
        "id": "e9e4e3fe-c620-4996-8650-1b1ff23d7c2f"
      },
      "source": [
        "$$\n",
        "\\frac{\\partial y}{\\partial x} = 2x\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2c4e6c9-baf3-4a81-aadc-f18c663e475b",
      "metadata": {
        "id": "b2c4e6c9-baf3-4a81-aadc-f18c663e475b"
      },
      "source": [
        "## Exercise 2:\n",
        "$$ y = tr(AB) \\quad A,B \\in \\mathbb{R}^{N \\times N} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d797ec60-7a09-44f3-847c-330817d3f2c3",
      "metadata": {
        "id": "d797ec60-7a09-44f3-847c-330817d3f2c3"
      },
      "source": [
        "$$\n",
        "\\frac{\\partial}{\\partial a_{ij}} y = b_{ji}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{dy}{dA} = B^T\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae9dfc9a-8260-4e7f-9d2e-b6ed5c793084",
      "metadata": {
        "id": "ae9dfc9a-8260-4e7f-9d2e-b6ed5c793084"
      },
      "source": [
        "## Exercise 3:\n",
        "$$  \n",
        "y = x^TAc , \\quad A\\in \\mathbb{R}^{N \\times N}, x\\in \\mathbb{R}^{N}, c\\in \\mathbb{R}^{N}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bd8c15f-d2bd-479a-834c-69028082c926",
      "metadata": {
        "id": "6bd8c15f-d2bd-479a-834c-69028082c926"
      },
      "source": [
        "$$\n",
        "\\frac{dy}{dA} = xc^T\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4cfbf67-96b4-440f-8a46-233ea2e99d7a",
      "metadata": {
        "id": "d4cfbf67-96b4-440f-8a46-233ea2e99d7a"
      },
      "source": [
        "## Exercise 4:\n",
        "$$\n",
        "J = || X - AS ||_2^2  , \\quad A\\in \\mathbb{R}^{N \\times R} , \\quad S\\in \\mathbb{R}^{R \\times M}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d326292-9bf6-442f-88cb-62020cf387fc",
      "metadata": {
        "id": "0d326292-9bf6-442f-88cb-62020cf387fc"
      },
      "source": [
        "$$\n",
        "\\frac{dJ}{dS} = 2(A^TAS - A^TX)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6fc8e8c-44f6-4300-a19c-7cba2471a5f1",
      "metadata": {
        "id": "a6fc8e8c-44f6-4300-a19c-7cba2471a5f1"
      },
      "source": [
        "# Part 1: Build Your Own Deep Learning Framework\n",
        "\n",
        "## Objective\n",
        "We have seen how to write a Neural Network using raw NumPy (hard) and PyTorch (easy). To truly understand what happens inside `loss.backward()`, you will build a mini-PyTorch from scratch using NumPy.\n",
        "\n",
        "## Instructions\n",
        "1.  **Do not use PyTorch, TensorFlow, or Autograd.** Use only `numpy`.\n",
        "2.  We provide the structure (`Module`, `Sequential`).\n",
        "3.  You must implement the `updateOutput` (Forward) and `updateGradInput`/`accGradParameters` (Backward) for:\n",
        "    * `Linear` (Dense Layer)\n",
        "    * `ReLU` (Activation)\n",
        "    * `SoftMax` (Activation)\n",
        "    * `CrossEntropyCriterion` (Loss)\n",
        "4.  Finally, train a model on the MNIST dataset using your framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40730a28-e182-45fb-945e-3f196f3b200e",
      "metadata": {
        "id": "40730a28-e182-45fb-945e-3f196f3b200e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Module(object):\n",
        "    \"\"\"\n",
        "    Abstract Class for a Neural Network Module.\n",
        "    \"\"\"\n",
        "    def __init__ (self):\n",
        "        self.output = None\n",
        "        self.gradInput = None\n",
        "        self.training = True\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Computes the output of the module.\n",
        "        \"\"\"\n",
        "        return self.updateOutput(input)\n",
        "\n",
        "    def backward(self, input, gradOutput):\n",
        "        \"\"\"\n",
        "        Performs a backpropagation step.\n",
        "        \"\"\"\n",
        "        self.updateGradInput(input, gradOutput)\n",
        "        self.accGradParameters(input, gradOutput)\n",
        "        return self.gradInput\n",
        "\n",
        "    def updateOutput(self, input):\n",
        "        \"\"\"\n",
        "        Specific to the module. Computes self.output\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def updateGradInput(self, input, gradOutput):\n",
        "        \"\"\"\n",
        "        Computing the gradient of the module with respect to its own input.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def accGradParameters(self, input, gradOutput):\n",
        "        \"\"\"\n",
        "        Computing the gradient of the module with respect to its own parameters.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def zeroGradParameters(self):\n",
        "        pass\n",
        "\n",
        "    def getParameters(self):\n",
        "        return []\n",
        "\n",
        "    def getGradParameters(self):\n",
        "        return []\n",
        "\n",
        "    def train(self):\n",
        "        self.training = True\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.training = False\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Module\"\n",
        "\n",
        "class Sequential(Module):\n",
        "    \"\"\"\n",
        "    A container that processes input sequentially through a list of modules.\n",
        "    \"\"\"\n",
        "    def __init__ (self):\n",
        "        super(Sequential, self).__init__()\n",
        "        self.modules = []\n",
        "\n",
        "    def add(self, module):\n",
        "        self.modules.append(module)\n",
        "\n",
        "    def updateOutput(self, input):\n",
        "        self.output = input\n",
        "        for module in self.modules:\n",
        "            self.output = module.forward(self.output)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, input, gradOutput):\n",
        "        # We need to pass the input of layer i to the backward of layer i\n",
        "        # But we only stored the final output in updateOutput.\n",
        "        # We need to re-compute or store intermediate inputs during forward.\n",
        "        # For simplicity here, let's re-run forward for inputs (naive)\n",
        "        # OR better: assume the user calls forward first and we can track inputs.\n",
        "\n",
        "        # NOTE for Students:\n",
        "        # In a real framework, we store inputs. Here, to keep it simple,\n",
        "        # we iterate backwards.\n",
        "\n",
        "        # 1. Get the inputs for each layer.\n",
        "        inputs = [input]\n",
        "        for i in range(len(self.modules) - 1):\n",
        "            inputs.append(self.modules[i].output)\n",
        "\n",
        "        # 2. Iterate backwards\n",
        "        self.gradInput = gradOutput\n",
        "        for i in range(len(self.modules) - 1, -1, -1):\n",
        "            self.gradInput = self.modules[i].backward(inputs[i], self.gradInput)\n",
        "\n",
        "        return self.gradInput\n",
        "\n",
        "    def zeroGradParameters(self):\n",
        "        for module in self.modules:\n",
        "            module.zeroGradParameters()\n",
        "\n",
        "    def getParameters(self):\n",
        "        return [x.getParameters() for x in self.modules]\n",
        "\n",
        "    def getGradParameters(self):\n",
        "        return [x.getGradParameters() for x in self.modules]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a166e86b-19fd-4231-b464-dd3a1b6ffbf6",
      "metadata": {
        "id": "a166e86b-19fd-4231-b464-dd3a1b6ffbf6"
      },
      "source": [
        "## Task 1: Linear Layer\n",
        "Implement the fully connected layer.\n",
        "Formula: $Y = X W^T + b$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b57e516c-7ba1-4747-859e-b8b20b2316de",
      "metadata": {
        "id": "b57e516c-7ba1-4747-859e-b8b20b2316de"
      },
      "outputs": [],
      "source": [
        "class Linear(Module):\n",
        "    def __init__(self, n_in, n_out):\n",
        "        super(Linear, self).__init__()\n",
        "\n",
        "        stdv = 1. / np.sqrt(n_in)\n",
        "        self.W = np.random.uniform(-stdv, stdv, size = (n_out, n_in))\n",
        "        self.b = np.random.uniform(-stdv, stdv, size = n_out)\n",
        "\n",
        "        self.gradW = np.zeros_like(self.W)\n",
        "        self.gradb = np.zeros_like(self.b)\n",
        "\n",
        "    def updateOutput(self, input):\n",
        "\n",
        "        self.output = input @ self.W.T + self.b\n",
        "        return self.output\n",
        "\n",
        "    def updateGradInput(self, input, gradOutput):\n",
        "\n",
        "        self.gradInput = gradOutput @ self.W\n",
        "        return self.gradInput\n",
        "\n",
        "    def accGradParameters(self, input, gradOutput):\n",
        "\n",
        "        self.gradW = gradOutput.T @ input\n",
        "        self.gradb = gradOutput.sum(axis=0)\n",
        "\n",
        "    def zeroGradParameters(self):\n",
        "        self.gradW.fill(0)\n",
        "        self.gradb.fill(0)\n",
        "\n",
        "    def getParameters(self):\n",
        "        return [self.W, self.b]\n",
        "\n",
        "    def getGradParameters(self):\n",
        "        return [self.gradW, self.gradb]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'Linear {self.W.shape[1]} -> {self.W.shape[0]}'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdae9ccf-29c7-403d-8471-e45182ad1be5",
      "metadata": {
        "id": "bdae9ccf-29c7-403d-8471-e45182ad1be5"
      },
      "source": [
        "## Task 2: Activation Functions\n",
        "Implement ReLU and SoftMax.\n",
        "**SoftMax Hint:** Subtract the max value from the input before exponentiating to avoid numerical overflow.\n",
        "$$\\text{SoftMax}(x_i) = \\frac{e^{x_i - \\max(x)}}{\\sum e^{x_j - \\max(x)}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "014f6645-019d-4280-b42a-d984a6a716b0",
      "metadata": {
        "id": "014f6645-019d-4280-b42a-d984a6a716b0"
      },
      "outputs": [],
      "source": [
        "class ReLU(Module):\n",
        "    def updateOutput(self, input):\n",
        "        # TODO: self.output = max(0, input)\n",
        "        self.output = np.maximum(0, input)\n",
        "        return self.output\n",
        "\n",
        "    def updateGradInput(self, input, gradOutput):\n",
        "\n",
        "        self.gradInput = np.where(input > 0, gradOutput, 0)\n",
        "\n",
        "        return self.gradInput\n",
        "\n",
        "class SoftMax(Module):\n",
        "    def updateOutput(self, input):\n",
        "\n",
        "        input_max = np.max(input, axis=1, keepdims=True)\n",
        "        input_exp = np.exp(input - input_max)\n",
        "        self.output = input_exp / np.sum(input_exp, axis=1, keepdims=True)\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    def updateGradInput(self, input, gradOutput):\n",
        "\n",
        "        softmax = self.output\n",
        "        self.gradInput = softmax * (gradOutput - np.sum(softmax * gradOutput, axis=1, keepdims=True))\n",
        "        return self.gradInput"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79d3b0cc-60d6-4f0b-82d2-e1489336e3c8",
      "metadata": {
        "id": "79d3b0cc-60d6-4f0b-82d2-e1489336e3c8"
      },
      "source": [
        "## Task 3: Criterion (Loss Function)\n",
        "Implement the Negative Log Likelihood (Cross Entropy) for multiclass classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f020cbb5-e3cd-4007-8d92-23a64daad401",
      "metadata": {
        "id": "f020cbb5-e3cd-4007-8d92-23a64daad401"
      },
      "outputs": [],
      "source": [
        "class ClassNLLCriterion(object):\n",
        "    def updateOutput(self, input, target):\n",
        "        # input: probability distribution (output of SoftMax)\n",
        "        # target: one-hot encoded or integer indices\n",
        "\n",
        "        # Use this trick to avoid numerical errors (log(0))\n",
        "        eps = 1e-15\n",
        "        input_clamp = np.clip(input, eps, 1 - eps)\n",
        "\n",
        "        # TODO: Calculate Negative Log Likelihood\n",
        "        self.output = -np.sum(target * np.log(input_clamp))\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    def updateGradInput(self, input, target):\n",
        "        # TODO: Calculate gradient\n",
        "        eps = 1e-15\n",
        "        input_clamp = np.clip(input, eps, 1 - eps)\n",
        "        self.gradInput = -target / input_clamp\n",
        "\n",
        "        return self.gradInput"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33e8b923-f393-41b9-8d6c-71619adbf326",
      "metadata": {
        "id": "33e8b923-f393-41b9-8d6c-71619adbf326"
      },
      "source": [
        "## Task 4: Putting it all together (MNIST)\n",
        "1. Load MNIST data (use `sklearn.datasets.load_digits` or `torchvision`).\n",
        "2. Preprocess: Normalize to [0,1], One-hot encode targets.\n",
        "3. Build a `Sequential` model: Linear -> ReLU -> Linear -> SoftMax.\n",
        "4. Write a training loop using SGD.\n",
        "5. Plot the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316f7d11-02ba-4b85-8b8a-1fb46ad9b0e1",
      "metadata": {
        "id": "316f7d11-02ba-4b85-8b8a-1fb46ad9b0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed91aae6-2e2b-493d-a42f-91f414408042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/200, Loss: 5.2680\n",
            "Epoch 10/200, Loss: 2.9064\n",
            "Epoch 15/200, Loss: 2.0460\n",
            "Epoch 20/200, Loss: 1.4117\n",
            "Epoch 25/200, Loss: 0.9613\n",
            "Epoch 30/200, Loss: 0.7395\n",
            "Epoch 35/200, Loss: 0.5835\n",
            "Epoch 40/200, Loss: 0.4877\n",
            "Epoch 45/200, Loss: 0.4101\n",
            "Epoch 50/200, Loss: 0.3221\n",
            "Epoch 55/200, Loss: 0.3006\n",
            "Epoch 60/200, Loss: 0.2571\n",
            "Epoch 65/200, Loss: 0.2190\n",
            "Epoch 70/200, Loss: 0.1953\n",
            "Epoch 75/200, Loss: 0.1717\n",
            "Epoch 80/200, Loss: 0.1524\n",
            "Epoch 85/200, Loss: 0.1476\n",
            "Epoch 90/200, Loss: 0.1352\n",
            "Epoch 95/200, Loss: 0.1226\n",
            "Epoch 100/200, Loss: 0.1176\n",
            "Epoch 105/200, Loss: 0.1059\n",
            "Epoch 110/200, Loss: 0.1008\n",
            "Epoch 115/200, Loss: 0.0954\n",
            "Epoch 120/200, Loss: 0.0903\n",
            "Epoch 125/200, Loss: 0.0843\n",
            "Epoch 130/200, Loss: 0.0785\n",
            "Epoch 135/200, Loss: 0.0742\n",
            "Epoch 140/200, Loss: 0.0722\n",
            "Epoch 145/200, Loss: 0.0678\n",
            "Epoch 150/200, Loss: 0.0655\n",
            "Epoch 155/200, Loss: 0.0634\n",
            "Epoch 160/200, Loss: 0.0599\n",
            "Epoch 165/200, Loss: 0.0580\n",
            "Epoch 170/200, Loss: 0.0553\n",
            "Epoch 175/200, Loss: 0.0532\n",
            "Epoch 180/200, Loss: 0.0517\n",
            "Epoch 185/200, Loss: 0.0494\n",
            "Epoch 190/200, Loss: 0.0470\n",
            "Epoch 195/200, Loss: 0.0463\n",
            "Epoch 200/200, Loss: 0.0444\n",
            "Test Accuracy: 97.22%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target.reshape(-1, 1)\n",
        "\n",
        "X = X / 16.0\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_onehot = encoder.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Linear(64,128))\n",
        "model.add(ReLU())\n",
        "model.add(Linear(128,10))\n",
        "model.add(SoftMax())\n",
        "\n",
        "loss_fn = ClassNLLCriterion()\n",
        "learning_rate = 0.01\n",
        "n_epochs = 200\n",
        "batch_size = 32\n",
        "\n",
        "loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    idx = np.random.permutation(len(X_train))\n",
        "    X_train = X_train[idx]\n",
        "    y_train = y_train[idx]\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        X_batch = X_train[i:i+batch_size]\n",
        "        y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "        probs = model.forward(X_batch)\n",
        "        loss = loss_fn.updateOutput(probs, y_batch)\n",
        "        epoch_loss += loss * X_batch.shape[0]\n",
        "\n",
        "        model.zeroGradParameters()\n",
        "        gradOutput = loss_fn.updateGradInput(probs, y_batch)\n",
        "        model.backward(X_batch, gradOutput)\n",
        "\n",
        "        for layer in model.modules:\n",
        "            for param, grad in zip(layer.getParameters(), layer.getGradParameters()):\n",
        "                param -= learning_rate * grad\n",
        "\n",
        "    epoch_loss /= len(X_train)\n",
        "    loss_history.append(epoch_loss)\n",
        "    if (epoch+1)%5==0:\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "\n",
        "model.evaluate()\n",
        "probs_test = model.forward(X_test)\n",
        "y_pred = np.argmax(probs_test, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "accuracy = np.mean(y_pred == y_true)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss (NLL)\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}